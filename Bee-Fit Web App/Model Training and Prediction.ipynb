{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdb6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all Library\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import  classification_report, accuracy_score, precision_score, recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4024b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CR_Data_Cleaned_V3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCR_Data_Cleaned_V3.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohsin\\Desktop\\Web_App\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohsin\\Desktop\\Web_App\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Mohsin\\Desktop\\Web_App\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohsin\\Desktop\\Web_App\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Mohsin\\Desktop\\Web_App\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CR_Data_Cleaned_V3.csv'"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "dataset = pd.read_csv(\"CR_Data_Cleaned_V3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cea17c",
   "metadata": {},
   "source": [
    "# Model Training phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_intensity(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan  # Keeps null values as null\n",
    "    elif value in [1, 2]:\n",
    "        return 'Low Intensity'\n",
    "    elif value in [3, 4]:\n",
    "        return 'Moderate Intensity'\n",
    "    elif value in [5, 6]:\n",
    "        return 'Moderately High Intensity'\n",
    "    elif value in [7, 8]:\n",
    "        return 'High Intensity'\n",
    "\n",
    "dataset['Exercise_intensityNew'] = dataset['Exercise_intensity'].apply(map_intensity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f35a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Race'].replace(['Others', 'Chinese', 'Malay', 'Indian', 'Unknown'],[0, 1, 2,3,4], inplace=True)\n",
    "dataset['Education_level'].replace(['Form 6 / pre-university graduate', 'Unknown', 'College/university graduate', 'Some secondary education', 'Form 5 graduate', 'Std 6 or less', 'Post-graduate', 'Technical graduate'],[0, 1, 2,3,4,5,6,7], inplace=True)\n",
    "dataset['Patient_occupation'].replace(['Government servant', 'Self-employed (excludes housewives)', 'Private employment'],[0, 1, 2], inplace=True)\n",
    "dataset['Health_funding'].replace(['Fully Funded', 'Self funded', 'Semi-Funded'], [0, 1, 2], inplace=True)\n",
    "dataset['CR_Intake'].replace(['Yes', 'No'], [0, 1], inplace=True)\n",
    "dataset['Prescribed_Sessions'].replace(['8 weeks', '> 8 weeks', 'Did Not Enroll CR', '6 weeks'], [0, 1, 2, 3], inplace=True)\n",
    "dataset['AACVPR_Risk_Category'].replace(['Low', 'Intermediate', 'High', 'Did Not Enroll CR', 'Unknown'], [0, 1, 2, 3, 4], inplace=True)\n",
    "dataset['CR_Adherence'].replace(['Yes', 'Did Not Enroll CR', 'No'], [0, 1, 2], inplace=True)\n",
    "dataset['Pre_Tobacco'].replace(['Never smoked', 'Former smoker', 'Current smoker'], [0, 1, 2], inplace=True)\n",
    "dataset['Post_Tobacco'].replace(['nan', 'Abstaining', 'Unknown', 'Not Abstaining'], [3, 0, 1, 2], inplace=True)\n",
    "dataset['Pre_Exercise_Stress_Test'].replace(['Treadmill', '6MWT only', 'Arm Ergo'], [0, 1, 2], inplace=True)\n",
    "dataset['Post_Exercise_Stress_Test'].replace(['Treadmill', '6MWT only', 'Arm Ergo', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "dataset['Gender'].replace(['Female', 'Male'], [0, 1], inplace=True)\n",
    "dataset['Pre_Left_Ventricle_EF'].replace(['nan', 'more then 50% with no failure symptoms', 'less then 40%', 'between 40 to 50%'], [3, 0, 1, 2], inplace=True)\n",
    "dataset['Triglyceride_cat'].replace(['Normal', 'High', 'Borderline high', 'Very High', 'nan'], [0, 1, 2, 3, 4], inplace=True)\n",
    "dataset['HDL_cat'].replace(['Intermediate risk', 'High Risk', 'Low risk', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "dataset['LDL_cat'].replace(['Intermediate risk', 'Low Risk', 'High risk', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "dataset['HbA1c_cat'].replace(['Normal', 'Prediabetes', 'Diabetes', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "dataset['Pre_BP_cat'].replace(['Optimal', 'Isolated Systolic Hypertension', 'At Risk', 'Normal', 'Hypertension Stage 1', 'Hypertension Stage 2', 'nan', 'Hypertension Stage 3'], [0, 1, 2, 3, 4, 5, 6, 7], inplace=True)\n",
    "dataset['CR_BP_cat'].replace(['Optimal', 'Normal', 'Isolated Systolic Hypertension', 'At Risk', 'nan', 'Hypertension Stage 1'], [0, 1, 2, 3, 4, 5], inplace=True)\n",
    "dataset['CR_Completion'].replace(['Yes', 'Did not enroll to CR', 'No'], [0, 1, 2], inplace=True)\n",
    "dataset['Pre_BMI_range'].replace(['Normal', 'Obesity', 'Overweight', 'nan', 'Underweight'], [0, 1, 2, 3, 4], inplace=True)\n",
    "dataset['Post_BMI_range'].replace(['Normal', 'Obesity', 'Overweight', 'nan', 'Underweight'], [0, 1, 2, 3, 4], inplace=True)\n",
    "dataset['Pre_Peak_Heart_Rate_range'].replace(['Moderate', 'nan', 'Hard', 'Light', 'Very Light', 'Very Hard'], [0, 1, 2, 3, 4, 5], inplace=True)\n",
    "dataset['Post_Peak_Heart_Rate_range'].replace(['nan', 'Very Light', 'Very Hard', 'Hard', 'Moderate', 'Light'], [1, 4, 5, 2, 0, 3], inplace=True)\n",
    "dataset['Pre_METs_range'].replace(['Vigorous Intensity', 'Moderate Intensity', 'Light Intensity', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "dataset['Post_Peak_METs_range'].replace(['nan', 'Vigorous Intensity', 'Moderate Intensity', 'Light Intensity'], [3, 0, 1, 2], inplace=True)\n",
    "dataset['place_name'].replace(\n",
    "    ['nan', 'Klang', 'Sungai Buloh', 'Kuala Lumpur, Pandan', 'Kuala Lumpur', 'Petaling Jaya', 'Subang Jaya',\n",
    "     'Kuala Lumpur, Gombak', 'Dong', 'Puchong, Sungai Buloh', 'Seremban', 'Kuala Selangor', 'Kuala Terengganu',\n",
    "     'Ampang', 'Shah Alam', 'Chini', 'Subang Jaya, Petaling Jaya', 'Seri Kembangan', 'Telok Panglima Garang',\n",
    "     'Batu Caves, Batu Caves', 'Kuala Lumpur, Cheras', 'Pelabuhan Klang', 'Miri', 'Hulu Langat', 'Nilai',\n",
    "     'Kuala Lumpur, Setapak', 'Semenyih', 'Ipoh', 'Melaka', 'Puchong', 'Rawang', 'Rawang, Batu Arang', 'Kajang'],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n",
    "    inplace=True\n",
    "\n",
    ")\n",
    "# Assuming dataset is your DataFrame\n",
    "dataset['state_name'].replace(\n",
    "    [np.nan, 'Selangor', 'Kuala Lumpur', 'Pahang', 'Negeri Sembilan', 'Terengganu', 'Sarawak', 'Perak', 'Melaka'],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    inplace=True\n",
    ")\n",
    "dataset['Exercise_intensityNew'].replace({\n",
    "    np.nan: np.nan,  # Keeps null values as null\n",
    "    'Low Intensity': 1,\n",
    "    'Moderate Intensity': 2,\n",
    "    'Moderately High Intensity': 3,\n",
    "    'High Intensity': 4\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47300bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Accuracy: 0.9130434782608695\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        24\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.76      0.90      0.83        21\n",
      "           3       0.96      1.00      0.98        26\n",
      "\n",
      "    accuracy                           0.91        92\n",
      "   macro avg       0.92      0.91      0.91        92\n",
      "weighted avg       0.92      0.91      0.91        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate the mean of the numeric columns, ignoring non-numeric ones\n",
    "numeric_means = dataset.select_dtypes(include=[np.number]).mean()\n",
    "\n",
    "# Perform mean imputation for all numeric columns except 'Exercise_intensityNew'\n",
    "columns_to_impute = dataset.columns.difference(['Exercise_intensityNew'])\n",
    "dataset[columns_to_impute] = dataset[columns_to_impute].fillna(numeric_means)\n",
    "\n",
    "# Calculate the mode for the 'Exercise_intensityNew' column\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "dataset['Exercise_intensityNew'] = mode_imputer.fit_transform(dataset[['Exercise_intensityNew']])\n",
    "\n",
    "# Convert 'Exercise_intensityNew' to integer type\n",
    "dataset['Exercise_intensityNew'] = dataset['Exercise_intensityNew'].astype(int)\n",
    "\n",
    "\n",
    "X = dataset.drop(['Exercise_intensity', 'Exercise_intensityNew'], axis=1)\n",
    "y = dataset['Exercise_intensityNew'] - 1\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_normalized = scaler.fit_transform(X_resampled)\n",
    "\n",
    "\n",
    "X_resampled = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Grid Search based SVM\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "\n",
    "svm_classifier = SVC()\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "\n",
    "svm_classifier = SVC(**best_params)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af538cbb",
   "metadata": {},
   "source": [
    "# Prediction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7699b63-0c64-434c-96c4-3786f1fa25c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0a203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Here instead of reading the csv file, it should read the data from db based on user input\n",
    "\n",
    "\n",
    "input_data = pd.read_csv(\"CR_Data_Cleaned_V3_Sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_intensity(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan  # Keeps null values as null\n",
    "    elif value in [1, 2]:\n",
    "        return 'Low Intensity'\n",
    "    elif value in [3, 4]:\n",
    "        return 'Moderate Intensity'\n",
    "    elif value in [5, 6]:\n",
    "        return 'Moderately High Intensity'\n",
    "    elif value in [7, 8]:\n",
    "        return 'High Intensity'\n",
    "\n",
    "input_data['Exercise_intensityNew'] = input_data['Exercise_intensity'].apply(map_intensity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['Race'].replace(['Others', 'Chinese', 'Malay', 'Indian', 'Unknown'],[0, 1, 2,3,4], inplace=True)\n",
    "input_data['Education_level'].replace(['Form 6 / pre-university graduate', 'Unknown', 'College/university graduate', 'Some secondary education', 'Form 5 graduate', 'Std 6 or less', 'Post-graduate', 'Technical graduate'],[0, 1, 2,3,4,5,6,7], inplace=True)\n",
    "input_data['Patient_occupation'].replace(['Government servant', 'Self-employed (excludes housewives)', 'Private employment'],[0, 1, 2], inplace=True)\n",
    "input_data['Health_funding'].replace(['Fully Funded', 'Self funded', 'Semi-Funded'], [0, 1, 2], inplace=True)\n",
    "input_data['CR_Intake'].replace(['Yes', 'No'], [0, 1], inplace=True)\n",
    "input_data['Prescribed_Sessions'].replace(['8 weeks', '> 8 weeks', 'Did Not Enroll CR', '6 weeks'], [0, 1, 2, 3], inplace=True)\n",
    "input_data['AACVPR_Risk_Category'].replace(['Low', 'Intermediate', 'High', 'Did Not Enroll CR', 'Unknown'], [0, 1, 2, 3, 4], inplace=True)\n",
    "input_data['CR_Adherence'].replace(['Yes', 'Did Not Enroll CR', 'No'], [0, 1, 2], inplace=True)\n",
    "input_data['Pre_Tobacco'].replace(['Never smoked', 'Former smoker', 'Current smoker'], [0, 1, 2], inplace=True)\n",
    "input_data['Post_Tobacco'].replace(['nan', 'Abstaining', 'Unknown', 'Not Abstaining'], [3, 0, 1, 2], inplace=True)\n",
    "input_data['Pre_Exercise_Stress_Test'].replace(['Treadmill', '6MWT only', 'Arm Ergo'], [0, 1, 2], inplace=True)\n",
    "input_data['Post_Exercise_Stress_Test'].replace(['Treadmill', '6MWT only', 'Arm Ergo', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "input_data['Gender'].replace(['Female', 'Male'], [0, 1], inplace=True)\n",
    "input_data['Pre_Left_Ventricle_EF'].replace(['nan', 'more then 50% with no failure symptoms', 'less then 40%', 'between 40 to 50%'], [3, 0, 1, 2], inplace=True)\n",
    "input_data['Triglyceride_cat'].replace(['Normal', 'High', 'Borderline high', 'Very High', 'nan'], [0, 1, 2, 3, 4], inplace=True)\n",
    "input_data['HDL_cat'].replace(['Intermediate risk', 'High Risk', 'Low risk', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "input_data['LDL_cat'].replace(['Intermediate risk', 'Low Risk', 'High risk', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "input_data['HbA1c_cat'].replace(['Normal', 'Prediabetes', 'Diabetes', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "input_data['Pre_BP_cat'].replace(['Optimal', 'Isolated Systolic Hypertension', 'At Risk', 'Normal', 'Hypertension Stage 1', 'Hypertension Stage 2', 'nan', 'Hypertension Stage 3'], [0, 1, 2, 3, 4, 5, 6, 7], inplace=True)\n",
    "input_data['CR_BP_cat'].replace(['Optimal', 'Normal', 'Isolated Systolic Hypertension', 'At Risk', 'nan', 'Hypertension Stage 1'], [0, 1, 2, 3, 4, 5], inplace=True)\n",
    "input_data['CR_Completion'].replace(['Yes', 'Did not enroll to CR', 'No'], [0, 1, 2], inplace=True)\n",
    "input_data['Pre_BMI_range'].replace(['Normal', 'Obesity', 'Overweight', 'nan', 'Underweight'], [0, 1, 2, 3, 4], inplace=True)\n",
    "input_data['Post_BMI_range'].replace(['Normal', 'Obesity', 'Overweight', 'nan', 'Underweight'], [0, 1, 2, 3, 4], inplace=True)\n",
    "input_data['Pre_Peak_Heart_Rate_range'].replace(['Moderate', 'nan', 'Hard', 'Light', 'Very Light', 'Very Hard'], [0, 1, 2, 3, 4, 5], inplace=True)\n",
    "input_data['Post_Peak_Heart_Rate_range'].replace(['nan', 'Very Light', 'Very Hard', 'Hard', 'Moderate', 'Light'], [1, 4, 5, 2, 0, 3], inplace=True)\n",
    "input_data['Pre_METs_range'].replace(['Vigorous Intensity', 'Moderate Intensity', 'Light Intensity', 'nan'], [0, 1, 2, 3], inplace=True)\n",
    "input_data['Post_Peak_METs_range'].replace(['nan', 'Vigorous Intensity', 'Moderate Intensity', 'Light Intensity'], [3, 0, 1, 2], inplace=True)\n",
    "input_data['place_name'].replace(\n",
    "    ['nan', 'Klang', 'Sungai Buloh', 'Kuala Lumpur, Pandan', 'Kuala Lumpur', 'Petaling Jaya', 'Subang Jaya',\n",
    "     'Kuala Lumpur, Gombak', 'Dong', 'Puchong, Sungai Buloh', 'Seremban', 'Kuala Selangor', 'Kuala Terengganu',\n",
    "     'Ampang', 'Shah Alam', 'Chini', 'Subang Jaya, Petaling Jaya', 'Seri Kembangan', 'Telok Panglima Garang',\n",
    "     'Batu Caves, Batu Caves', 'Kuala Lumpur, Cheras', 'Pelabuhan Klang', 'Miri', 'Hulu Langat', 'Nilai',\n",
    "     'Kuala Lumpur, Setapak', 'Semenyih', 'Ipoh', 'Melaka', 'Puchong', 'Rawang', 'Rawang, Batu Arang', 'Kajang'],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n",
    "    inplace=True\n",
    "\n",
    ")\n",
    "# Assuming input_data is your DataFrame\n",
    "input_data['state_name'].replace(\n",
    "    [np.nan, 'Selangor', 'Kuala Lumpur', 'Pahang', 'Negeri Sembilan', 'Terengganu', 'Sarawak', 'Perak', 'Melaka'],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    inplace=True\n",
    ")\n",
    "input_data['Exercise_intensityNew'].replace({\n",
    "    np.nan: np.nan,  # Keeps null values as null\n",
    "    'Low Intensity': 1,\n",
    "    'Moderate Intensity': 2,\n",
    "    'Moderately High Intensity': 3,\n",
    "    'High Intensity': 4\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Game Difficulty: Medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Impute missing values if necessary\n",
    "columns_to_impute = input_data.columns.difference(['Exercise_intensityNew'])\n",
    "input_data[columns_to_impute] = input_data[columns_to_impute].fillna(numeric_means)\n",
    "\n",
    "# Standardize the features using the same scaler used in training\n",
    "# Note: Use the scaler that was fitted on the training data\n",
    "X_normalized = scaler.transform(input_data.drop(['Exercise_intensity', 'Exercise_intensityNew'], axis=1))\n",
    "\n",
    "# Predict using the trained SVM classifier\n",
    "predicted_numerical_intensity = svm_classifier.predict(X_normalized)\n",
    "\n",
    "# Map the prediction to the corresponding intensity and then to game difficulty\n",
    "intensity_mapping = {1: 'Low Intensity', 2: 'Moderate Intensity', 3: 'Moderately High Intensity', 4: 'High Intensity'}\n",
    "predicted_intensity = intensity_mapping.get(predicted_numerical_intensity[0], 'Unknown')\n",
    "\n",
    "def map_to_game_difficulty(predicted_intensity):\n",
    "    mapping = {\n",
    "        'Low Intensity': 'Easy',\n",
    "        'Moderate Intensity': 'Medium',\n",
    "        'Moderately High Intensity': 'Hard',\n",
    "        'High Intensity': 'Expert',\n",
    "        'Unknown': 'Medium'  # Default to 'Medium' if the intensity is unknown\n",
    "    }\n",
    "    return mapping.get(predicted_intensity, 'Unknown Difficulty')\n",
    "\n",
    "game_difficulty = map_to_game_difficulty(predicted_intensity)\n",
    "print(f\"Predicted Game Difficulty: {game_difficulty}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
